{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28696267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from datetime import datetime\n",
    "from IPython import display\n",
    "from collections import Counter\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afad64",
   "metadata": {},
   "source": [
    "# Background\n",
    "This notebook ensures that the model results are replicatable. The other notebooks in this repo show the entire data science process for building the model and cleaning the data. You will only need the serialized data that is good to go. See the next cells for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216063e",
   "metadata": {},
   "source": [
    "[Pickle Documentation](https://docs.python.org/3/library/pickle.html)\n",
    "<br>\n",
    "The cleaned, preprocessed, and resampled data for final use is pickled into objects called X_final which is the vectorized text data and y_final which is the label encoded data that represents the different IT teams. By reading this into your environment, you now have this available for use (as long as it is in your working directory). These pickle objects are the only data in the repo, not the actual raw data itself. This notebook will be the only replicatable one, since the master notebook requires the raw data (which is not available in the repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0867736",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_final.pickle', 'rb') as f: \n",
    "    X_final = pickle.load(f)\n",
    "    \n",
    "with open('y_final.pickle', 'rb') as f: \n",
    "    y_final = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb483c",
   "metadata": {},
   "source": [
    "After we have read in our data, we will train and test our model by splitting our data into two different sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58ac869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, valid sets\n",
    "train_X, valid_X, train_y, valid_y= train_test_split(X_final, y_final, random_state = 42, test_size=0.2)\n",
    "\n",
    "#create model and specify parameters\n",
    "model = Pipeline([('tfidf', TfidfVectorizer(max_features=10000, max_df=0.75, min_df=2,\n",
    "                                            stop_words=stopwords.words('english'), ngram_range=(1,2))),\n",
    "                ('clf', LogisticRegression(penalty='l2', solver='liblinear', class_weight='balanced', C=10, random_state=42)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3487dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      3015\n",
      "           1       0.90      0.96      0.93      1696\n",
      "           2       0.86      0.79      0.82      5047\n",
      "           3       0.82      0.86      0.84      1763\n",
      "           4       0.92      0.94      0.93      2336\n",
      "           5       0.97      0.96      0.96      1995\n",
      "           6       0.80      0.84      0.82      2394\n",
      "           7       0.84      0.86      0.85      1954\n",
      "\n",
      "    accuracy                           0.88     20200\n",
      "   macro avg       0.88      0.90      0.89     20200\n",
      "weighted avg       0.88      0.88      0.88     20200\n",
      "\n",
      "Micro Average Precision Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "#train our model\n",
    "model.fit(train_X, train_y)\n",
    "#test results \n",
    "pred_y = model.predict(valid_X)\n",
    "#compare test results to actual and create confusion matrix\n",
    "print(classification_report(valid_y, pred_y))\n",
    "cm=confusion_matrix(valid_y, pred_y)\n",
    "\n",
    "#specify the metric we want to see: precision\n",
    "pc_micro = (precision_score(valid_y, pred_y, average=\"micro\"))\n",
    "print('Micro Average Precision Score: {0:.2g}'.format(pc_micro))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06187326",
   "metadata": {},
   "source": [
    "We get precision as the metric we optimize for as we are trying to reduce False Positives. More on this [here](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11192568",
   "metadata": {},
   "source": [
    "Next, since have the results we want. We will fit the model to all our data instead of the partitions of train/test we did prior. This is the final model used in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1036e82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.75, max_features=10000, min_df=2,\n",
       "                                 ngram_range=(1, 2),\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=10, class_weight='balanced',\n",
       "                                    random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = Pipeline([('tfidf', TfidfVectorizer(max_features=10000, max_df=0.75, min_df=2,\n",
    "                                            stop_words=stopwords.words('english'), ngram_range=(1,2))),\n",
    "                ('clf', LogisticRegression(penalty='l2', solver='liblinear', class_weight='balanced', C=10, random_state=42)),\n",
    "               ])\n",
    "\n",
    "final_model.fit(X_final, y_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3284a61",
   "metadata": {},
   "source": [
    "We save our final model for future use by pickling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bdc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving classifier\n",
    "with open ('final_model.pickle','wb') as f:#wb, write-byte\n",
    "    pickle.dump (final_model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb80d9",
   "metadata": {},
   "source": [
    "# How our Model works in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702f43b",
   "metadata": {},
   "source": [
    "The following cells show how when in production, the user will input text which will be passed to the data. Remember, since we are dealing with raw text, we need to normalze it as vectors, which will be done through a normalization pipeline shown below. Then we can apply our model and receive a prediction/class probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0fd2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt=nltk.WordPunctTokenizer()\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#normalization pipeline\n",
    "def normalize_doc(doc):\n",
    "    doc=re.sub(r'[^a-zA-Z\\s]', '', doc) \n",
    "    doc=doc.lower() \n",
    "    doc=doc.strip() \n",
    "    tokens=wpt.tokenize(doc)\n",
    "    filtered_tokens=[token for token in tokens if token not in stop_words]\n",
    "    doc=' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ae00a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user input field\n",
    "sample_text = ['SL2 self checkout printer not functioning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e595ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new clean text to dataframe\n",
    "normalize_corpus=np.vectorize(normalize_doc) #create a vectorized object for our normalization pipeline\n",
    "norm_text=normalize_corpus(sample_text) #clean and normalize the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a3cbcdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sl self checkout printer functioning'], dtype='<U36')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalized text befor text extraction\n",
    "norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8a88ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access the steps of our finalized model to apply to a single ticket\n",
    "vect=final_model.named_steps['tfidf']\n",
    "clf=final_model.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2fa3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "trans_text=vect.transform(norm_text).toarray() #apply text extraction using TFIDF \n",
    "print(clf.predict(trans_text)) #apply logistic regression model classifier to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674a64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_corpus=np.vectorize(normalize_doc) #create a vectorized object for our normalization pipeline\n",
    "norm_text=normalize_corpus(sample_text) #clean and normalize the ticket\n",
    "\n",
    "vect=final_model.named_steps['tfidf']\n",
    "clf=final_model.named_steps['clf']\n",
    "\n",
    "trans_text=vect.transform(norm_text).toarray()\n",
    "prediction=clf.predict(trans_text)\n",
    "probabilities=(clf.predict_proba(trans_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f344d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction(label_prediction):\n",
    "    #identify the class prediction \n",
    "    if label_prediction==0:\n",
    "        owner='EAM & MRO Inventory Support'\n",
    "    elif label_prediction==1:\n",
    "        owner='HRIS Team'\n",
    "    elif label_prediction==2: \n",
    "        owner='IT Service Desk Team'\n",
    "    elif label_prediction==3:\n",
    "        owner='Network Team'\n",
    "    elif label_prediction==4:\n",
    "        owner='OTM Support'\n",
    "    elif label_prediction==5:\n",
    "        owner='Planning Support'\n",
    "    elif label_prediction==6:\n",
    "        owner='System Admin Team'\n",
    "    else:\n",
    "        owner='WMS Team'\n",
    "    return print(owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59274cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMS Team\n"
     ]
    }
   ],
   "source": [
    "output_prediction(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "224d88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probabilities(array_prob):\n",
    "    prob_classes=array_prob[0][:]\n",
    "    prob_classes_num = [\"{:.2%}\".format(prob) for prob in prob_classes]\n",
    "    \n",
    "    classes = ['EAM & MRO Inventory Support', 'HRIS Team', 'IT Service Desk Team', 'Network Team', 'OTM Support', \n",
    "          'Planning Support', 'System Admin Team', 'WMS Team']\n",
    "    ownerDict = dict(zip(classes, prob_classes_num))\n",
    "    ownerDf = pd.DataFrame(ownerDict.items(), columns=['Owner', 'Probability'])\n",
    "    \n",
    "    return(ownerDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ab23d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAM &amp; MRO Inventory Support</td>\n",
       "      <td>0.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRIS Team</td>\n",
       "      <td>0.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT Service Desk Team</td>\n",
       "      <td>16.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network Team</td>\n",
       "      <td>5.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTM Support</td>\n",
       "      <td>0.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Planning Support</td>\n",
       "      <td>0.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>System Admin Team</td>\n",
       "      <td>1.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WMS Team</td>\n",
       "      <td>76.28%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Owner Probability\n",
       "0  EAM & MRO Inventory Support       0.06%\n",
       "1                    HRIS Team       0.04%\n",
       "2         IT Service Desk Team      16.78%\n",
       "3                 Network Team       5.16%\n",
       "4                  OTM Support       0.05%\n",
       "5             Planning Support       0.03%\n",
       "6            System Admin Team       1.59%\n",
       "7                     WMS Team      76.28%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probabilities(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
